{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nlp2.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMANSY8l2LdkLmu4rDNytv4"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"vJaUNa__way6","colab_type":"code","outputId":"9a156c6d-6d6a-448f-da03-e79998d20d4a","executionInfo":{"status":"ok","timestamp":1588393446848,"user_tz":-270,"elapsed":70715,"user":{"displayName":"Peter YounanoAdeh","photoUrl":"","userId":"06313006438386438224"}},"colab":{"base_uri":"https://localhost:8080/","height":289}},"source":["!pip install git+https://github.com/dabeaz/sly\n","from sly import Lexer\n","\n","import io\n","import re\n","import glob\n","import pandas as pd\n","\n","# mount google drive to access files\n","from google.colab import drive\n","path = \"/gdrive/My Drive/Colab Notebooks/nlp\"\n","\n","drive.mount('/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting git+https://github.com/dabeaz/sly\n","  Cloning https://github.com/dabeaz/sly to /tmp/pip-req-build-8vli1rfd\n","  Running command git clone -q https://github.com/dabeaz/sly /tmp/pip-req-build-8vli1rfd\n","Building wheels for collected packages: sly\n","  Building wheel for sly (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sly: filename=sly-0.4-cp36-none-any.whl size=28331 sha256=3e14c7bebb5640dbc8bbb416d177eaac7e3ed1cac145ac34a21cd90a29aa62ae\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-rtj_a0zf/wheels/fd/a1/a0/07789f27b5fa3cab050b37f60193d3b28f26b2d6497cbf4097\n","Successfully built sly\n","Installing collected packages: sly\n","Successfully installed sly-0.4\n","Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"RQfZDd2hyWG2","colab_type":"code","colab":{}},"source":["def convert_ar_characters(input_str):\n","    \"\"\"\n","    Converts Arabic chars to related Persian unicode char\n","    :param input_str: String contains Arabic chars\n","    :return: New str with converted arabic chars\n","    \"\"\"\n","    mapping = {\n","        'ك' : 'ک',\n","        'دِ' : 'د',\n","        'بِ' : 'ب',\n","        'زِ' : 'ز',\n","        'ذِ' : 'ذ',\n","        'شِ' : 'ش',\n","        'سِ' : 'س',\n","        'ى' : 'ی',\n","        'ي' : 'ی',\n","        '“' : '\"',\n","        '”' : '\"',\n","        ')' : '(',\n","        '(' : ')',\n","        ')' : '(',\n","        '٠' : '0', # arabic numbers\n","        '١' : '1',\n","        '٢' : '2',\n","        '٣' : '3',\n","        '٤' : '4',\n","        '٥' : '5',\n","        '٦' : '6',\n","        '٧' : '7',\n","        '٨' : '8',\n","        '٩' : '9',\n","        '۰' : '0', # persian numbers\n","        '۱' : '1',\n","        '۲' : '2',\n","        '۳' : '3',\n","        '۴' : '4',\n","        '۵' : '5',\n","        '۶' : '6',\n","        '۷' : '7',\n","        '۸' : '8',\n","        '۹' : '9',\n","        'ـ' : '',\n","        '–' : '-',\n","        'ة' : 'ه',\n","        'ؤ' : 'و',\n","        'ي' : 'ی',\n","        'إ' : 'ا',\n","        'أ' : 'ا',\n","        'ئ' : 'ی',\n","        'ۀ' : 'ه',\n","        'هٔ' : 'ه\\u200cی',\n","        '\\u200e' : '\\u200c',\n","        '\\u064e' : '',\n","        '\\u0650' : '',\n","        '\\u064b' : '',\n","        '\\u0652' : '',\n","        '\\u064e' : '',\n","        '\\u0650' : '',\n","        '\\u064d' : '',\n","        '\\u064c' : '',\n","        '\\u064b' : '',\n","        '\\u064f' : '',\n","        '٬' : ',',\n","    }\n","    return _multiple_replace(mapping, input_str)\n","\n","\n","def _multiple_replace(mapping, text):\n","    \"\"\"\n","    Internal function for replace all mapping keys for a input string\n","    :param mapping: replacing mapping keys\n","    :param text: user input string\n","    :return: New string with converted mapping keys to values\n","    \"\"\"\n","    pattern = \"|\".join(map(re.escape, mapping.keys()))\n","    return re.sub(pattern, lambda m: mapping[m.group()], str(text))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KZMIwA49Zhl2","colab_type":"code","colab":{}},"source":["class Tokenizer(Lexer):\n","    tokens = { EMOJI, ABBREVIATION, DATE, TIME, IP, SPACIALNAMES, EMAIL, URL, TAG, ENGLISH, PERSIAN, PERCENT, FLOAT, THUSANDSCOMMA, NUMBER, MATHCHAR, LPAREN, RPAREN, LBRAKET, RBRAKET, LOTHER, ROTHER, PUNCTION, INVALID }\n","    ignore = ' \\t\\u200f\\ufeff\\ufe0f'\n","\n","    # Tokens\n","    EMOJI = r'[\\U0001F1E0-\\U0001F1FF\\U0001F300-\\U0001F5FF\\U0001F600-\\U0001F64F\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0\\U000024C2-\\U0001F251]([\\u200d][\\U0001F1E0-\\U0001F1FF\\U0001F300-\\U0001F5FF\\U0001F600-\\U0001F64F\\U0001F680-\\U0001F6FF\\U0001F700-\\U0001F77F\\U0001F780-\\U0001F7FF\\U0001F800-\\U0001F8FF\\U0001F900-\\U0001F9FF\\U0001FA00-\\U0001FA6F\\U0001FA70-\\U0001FAFF\\U00002702-\\U000027B0\\U000024C2-\\U0001F251])*'\n","    ABBREVIATION = r'([A-Z]\\.){2,}'\n","    DATE = r'^([1-9]|0[1-9]|1[0-9]|2[0-9]|3[0-1])(\\.|-|/)([1-9]|0[1-9]|1[0-2])(\\.|-|/)([0-9][0-9]|[0-9][0-9][0-9]|[0-9][0-9][0-9][0-9])$|^([0-9][0-9]|[0-9][0-9][0-9]|[0-9][0-9][0-9][0-9])(\\.|-|/)([1-9]|0[1-9]|1[0-2])(\\.|-|/)([1-9]|0[1-9]|1[0-9]|2[0-9]|3[0-1])$'\n","    TIME = r'^(1[0-2]|0?[1-9]):([0-5]?[0-9])(●?[AP]M)?$|^(2[0-3]|[01]?[0-9]):([0-5]?[0-9])$|^(1[0-2]|0?[1-9]):([0-5]?[0-9]):([0-5]?[0-9])(●?[AP]M)?$|^(2[0-3]|[01]?[0-9]):([0-5]?[0-9]):([0-5]?[0-9])$'\n","    IP = r'((telnet://)|)[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}\\.[0-9]{1,3}(/[0-9]{1,2})?'\n","    SPACIALNAMES = r'((\\.(net)|(NET)|(Net))|([Cc]#|[Cc]\\+\\+)|(3[Gg])|(4[Gg][+]?))'\n","    EMAIL = r'[a-zA-Z0-9_.+-]+@[ا-یآa-zA-Z0-9-]+\\.(?:com|net|org|edu|gov|ir|co|info|blog|club|llc|us|shop|opr|app|inc|website|uk|de|icu|me|tr|mil|arpa|gl|gr|ly)+'\n","    URL = r'(((http(s)?://)|(ftp://)|(ldap://)|(mailto:)|(news:)|)[?آا-یa-zA-Z0-9%\\.\\~\\(\\)\\*\\'&\\+=!@_\\#-]+(?:\\.com|\\.net|\\.org|\\.edu|\\.gov|\\.ir|\\.co|\\.info|\\.blog|\\.club|\\.llc|\\.us|\\.shop|\\.opr|\\.app|\\.inc|\\.website|\\.uk|\\.de|\\.icu|\\.me|\\.tr|\\.mil|\\.arpa|\\.gl|\\.gr|\\.ly)+([/][آا-یa-zA-Z0-9%\\.\\~\\(\\)\\*\\'&\\+=!@_\\#-?]*)*)'\n","    TAG = r'[\\#@][?آا-یa-zA-Z0-9%\\.\\~\\(\\)\\*\\'&\\+=!@_-]+'\n","    ENGLISH = r'([a-zA-Z]+([-_][a-zA-Z]+)*)[a-zA-Z][™©®]?'\n","    PERSIAN = r'[ئا-یآء][ئا-ی\\u200cّءآ_]*[ئا-یآء]'\n","    PERCENT = r'[-]?\\d*[.\\\\]?d+%'\n","    FLOAT = r'[-]?\\d*[\\.\\\\]\\d+'\n","    THUSANDSCOMMA = r'(?<!,)\\b(\\d{1,3}(?:,\\d{3})*)\\b(?!,)'\n","    NUMBER = r'[-]?\\d+'\n","\n","    # Special symbols\n","    MATHCHAR = r'[\\+\\-\\*/=\\^%]'\n","    LPAREN = r'\\('\n","    RPAREN = r'\\)'\n","    LBRAKET = r'\\['\n","    RBRAKET = r'\\]'\n","    LOTHER = r'[«{→]'\n","    ROTHER = r'[»}←]'\n","    PUNCTION = r'[,\\.\\':;.،!:?؛؟\"•▪…|@$#~`]'\n","\n","    INVALID = r'.'\n","\n","\n","    # Ignored pattern\n","    ignore_newline = r'\\n+'\n","\n","    # Extra action for newlines\n","    def ignore_newline(self, t):\n","        self.lineno += t.value.count('\\n')\n","\n","    def error(self, t):\n","        print(\"Illegal character '%s'\" % t.value[0])\n","        self.index += 1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_of7jkA_aJK1","colab_type":"code","outputId":"a4f3adf1-b796-495d-a973-22963e7b861f","executionInfo":{"status":"ok","timestamp":1588393634769,"user_tz":-270,"elapsed":7358,"user":{"displayName":"Peter YounanoAdeh","photoUrl":"","userId":"06313006438386438224"}},"colab":{"base_uri":"https://localhost:8080/","height":402}},"source":["# load all files in directory\n","files = glob.glob(f'{path}/big/*.txt')\n","fileCount = len(files)\n","# create place holder data frame to hold information of all files\n","data = pd.DataFrame(columns=['Word'])\n","\n","# proccess each file\n","for i, filename in enumerate(files):\n","   with io.open(filename, mode=\"r\", encoding=\"utf-8\") as f:\n","    text = ''\n","    for x in f:\n","      text = text + x\n","\n","    text = convert_ar_characters(text)\n","    tokenizer = Tokenizer()      \n","    dic = {}\n","    prev = ''\n","    prevType = ''\n","    for token in tokenizer.tokenize(text):\n","      index = -1 \n","      while True:\n","          index = token.value.find('\\u200c', index + 1)\n","          if index == -1:\n","              break\n","          if token.value[index-1] in {'ا', 'د', 'ذ', 'ر', 'ز'}:\n","            token.value = token.value[:index] + token.value[index+1:]\n","      if token.value in {'ها', 'های', 'ها\\u200cی', 'تر', 'ترین', 'ی'} and prevType == 'PERSIAN':\n","        if prev[-1] in {'ا', 'د', 'ذ', 'ر', 'ز'}:\n","          prev = prev + token.value\n","        else:\n","          prev = prev + '\\u200c' + token.value\n","        try:\n","          dic[prev] = dic[prev] + 1\n","        except:\n","          dic[prev] = 1\n","        prev = ''\n","        prevType = ''\n","      elif prev in {'می', 'نمی'} and token.type == 'PERSIAN':\n","        prev = prev + '\\u200c' + token.value\n","        prevType = 'PERSIAN'\n","      else:\n","        if prev != '':\n","          if prev[-1] == '\\u200c':\n","            prev = prev[:-1]\n","          try:\n","            dic[prev] = dic[prev] + 1\n","          except:\n","            dic[prev] = 1\n","        prev = token.value\n","        prevType = token.type\n","    if prev != '':\n","          if prev[-1] == '\\u200c':\n","            prev = prev[:-1]\n","          try:\n","            dic[prev] = dic[prev] + 1\n","          except:\n","            dic[prev] = 1\n","    # convert dictionary to data frame for better management      \n","    df = pd.DataFrame(list(dic.items()))\n","    # rename columns\n","    df = df.rename(columns={0:'Word', 1:f'{i+1} TF'})\n","    # join data frame of current file with data frame of all files\n","    data = pd.merge(data, df, on = ['Word'], how = 'outer').fillna(0)\n","\n","data"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Word</th>\n","      <th>1 TF</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Text</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>🔸</td>\n","      <td>8354</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>شان</td>\n","      <td>98</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>اسپایسر</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>سخنگوی</td>\n","      <td>288</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>34875</th>\n","      <td>می‌انجامید</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>34876</th>\n","      <td>پایه‌ی</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>34877</th>\n","      <td>مقنّنه</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>34878</th>\n","      <td>1954</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>34879</th>\n","      <td>پورt.co/W3VZpO4DOt@tTalabe</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>34880 rows × 2 columns</p>\n","</div>"],"text/plain":["                             Word  1 TF\n","0                            Text     1\n","1                               🔸  8354\n","2                             شان    98\n","3                         اسپایسر     3\n","4                          سخنگوی   288\n","...                           ...   ...\n","34875                  می‌انجامید     1\n","34876                      پایه‌ی     1\n","34877                      مقنّنه     1\n","34878                        1954     1\n","34879  پورt.co/W3VZpO4DOt@tTalabe     1\n","\n","[34880 rows x 2 columns]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"ulerHLCKPaeW","colab_type":"code","outputId":"e0f19fd7-c0d8-445c-cc1d-3c92a4d242f2","executionInfo":{"status":"ok","timestamp":1588393634770,"user_tz":-270,"elapsed":7082,"user":{"displayName":"Peter YounanoAdeh","photoUrl":"","userId":"06313006438386438224"}},"colab":{"base_uri":"https://localhost:8080/","height":402}},"source":["# convert data to boolean and sum them on rows to get number of docs with that word (minus one is to reduce word itself)\n","data[\"DF\"] = data.astype(bool).sum(axis=1) - 1\n","for i in range(1, fileCount+1):\n","  data[f'{i} TF-IDF'] = data[f'{i} TF'] / data['DF']\n","\n","data = data[data['DF'] != 0]\n","data = data.sort_values(by=['Word'])\n","data"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Word</th>\n","      <th>1 TF</th>\n","      <th>DF</th>\n","      <th>1 TF-IDF</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>31893</th>\n","      <td>\u0010</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>2.0</td>\n","    </tr>\n","    <tr>\n","      <th>350</th>\n","      <td>!</td>\n","      <td>2469</td>\n","      <td>1</td>\n","      <td>2469.0</td>\n","    </tr>\n","    <tr>\n","      <th>32901</th>\n","      <td>!!!!twitter.com/AadamEbneHavva/status/87236257...</td>\n","      <td>5</td>\n","      <td>1</td>\n","      <td>5.0</td>\n","    </tr>\n","    <tr>\n","      <th>31341</th>\n","      <td>!!!twitter.com/a_a_kh1981/status/8716736383360...</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>11597</th>\n","      <td>!#قیام_طبرستانRajanews.com</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>6408</th>\n","      <td>🤼‍♂</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>29269</th>\n","      <td>🥀</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1.0</td>\n","    </tr>\n","    <tr>\n","      <th>21250</th>\n","      <td>🥇</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>21251</th>\n","      <td>🥈</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","    </tr>\n","    <tr>\n","      <th>21252</th>\n","      <td>🥉</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>34879 rows × 4 columns</p>\n","</div>"],"text/plain":["                                                    Word  1 TF  DF  1 TF-IDF\n","31893                                                  \u0010     2   1       2.0\n","350                                                    !  2469   1    2469.0\n","32901  !!!!twitter.com/AadamEbneHavva/status/87236257...     5   1       5.0\n","31341  !!!twitter.com/a_a_kh1981/status/8716736383360...     1   1       1.0\n","11597                         !#قیام_طبرستانRajanews.com     1   1       1.0\n","...                                                  ...   ...  ..       ...\n","6408                                                 🤼‍♂     1   1       1.0\n","29269                                                  🥀     1   1       1.0\n","21250                                                  🥇     3   1       3.0\n","21251                                                  🥈     3   1       3.0\n","21252                                                  🥉     3   1       3.0\n","\n","[34879 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"kzI9EXmDBrXX","colab_type":"code","colab":{}},"source":["data.to_csv(f'{path}/output.csv', index=False, encoding='utf-8-sig')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dc-5aOJv3fPO","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}