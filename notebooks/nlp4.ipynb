{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"nlp4.ipynb","provenance":[],"authorship_tag":"ABX9TyNpc+d+sMJTv+0SU1Ikq62f"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"xvfjo75XYwV_","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592636413939,"user_tz":-270,"elapsed":3028,"user":{"displayName":"Peter YounanoAdeh","photoUrl":"","userId":"06313006438386438224"}}},"source":["import nltk\n","import numpy as np\n","import pandas as pd\n","import random\n","from sklearn.model_selection import train_test_split"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"9dMufSdTY66W","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":84},"executionInfo":{"status":"ok","timestamp":1592636418535,"user_tz":-270,"elapsed":7606,"user":{"displayName":"Peter YounanoAdeh","photoUrl":"","userId":"06313006438386438224"}},"outputId":"369db9c5-764b-444e-d6e3-af9902b42c54"},"source":["#download the treebank corpus from nltk\n","nltk.download('treebank')\n","\n","#download the universal tagset from nltk\n","nltk.download('universal_tagset')\n","\n","# reading the Treebank tagged sentences\n","nltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))\n","\n","# split data into training and validation set in the ratio 80:20\n","train_datasets,test_datasets =train_test_split(nltk_data,train_size=0.80,test_size=0.20,random_state = 101)\n","\n","# create list of train and test tagged words\n","train_tagged_words = [ tup for sent in train_datasets for tup in sent ]\n","test_tagged_words = [ tup for sent in test_datasets for tup in sent ]\n","\n","#use set datatype to check how many unique tags are present in training data\n","tags = {tag for word,tag in train_tagged_words}"],"execution_count":2,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package treebank to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/treebank.zip.\n","[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n","[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZHjK4gn6ZBDQ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592636418536,"user_tz":-270,"elapsed":7603,"user":{"displayName":"Peter YounanoAdeh","photoUrl":"","userId":"06313006438386438224"}}},"source":["# compute Emission Probability\n","def word_given_tag(word, tag, train_bag = train_tagged_words):\n","    tag_list = [pair for pair in train_bag if pair[1]==tag]\n","    count_tag = len(tag_list)#total number of times the passed tag occurred in train_bag\n","    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n","    #now calculate the total number of times the passed word occurred as the passed tag.\n","    count_w_given_tag = len(w_given_tag_list)\n","    \n","    return (count_w_given_tag, count_tag)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"vpEixsZ4ZDdN","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592636418537,"user_tz":-270,"elapsed":7600,"user":{"displayName":"Peter YounanoAdeh","photoUrl":"","userId":"06313006438386438224"}}},"source":["# compute  Transition Probability\n","def t2_given_t1(t2, t1, train_bag = train_tagged_words):\n","    tags = [pair[1] for pair in train_bag]\n","    count_t1 = len([t for t in tags if t==t1])\n","    count_t2_t1 = 0\n","    for index in range(len(tags)-1):\n","        if tags[index]==t1 and tags[index+1] == t2:\n","            count_t2_t1 += 1\n","    return (count_t2_t1, count_t1)"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"eWeVk--ZZFHG","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592636421689,"user_tz":-270,"elapsed":10748,"user":{"displayName":"Peter YounanoAdeh","photoUrl":"","userId":"06313006438386438224"}}},"source":["# creating t x t transition matrix of tags, t= no of tags\n","# Matrix(i, j) represents P(jth tag after the ith tag)\n","tags_matrix = np.zeros((len(tags), len(tags)), dtype='float32')\n","for i, t1 in enumerate(list(tags)):\n","    for j, t2 in enumerate(list(tags)): \n","        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]/t2_given_t1(t2, t1)[1]\n","\n","tags_df = pd.DataFrame(tags_matrix, columns = list(tags), index=list(tags))"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2dbzI4ClDDtN","colab_type":"text"},"source":["Viterbi algoritm is an algorith used to find the most likely sequance of hidden states and is used to find sequence of hidden markov model"]},{"cell_type":"code","metadata":{"id":"EELo1AEmvLBh","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1592636421691,"user_tz":-270,"elapsed":10745,"user":{"displayName":"Peter YounanoAdeh","photoUrl":"","userId":"06313006438386438224"}}},"source":["def Viterbi(words, train_bag = train_tagged_words):\n","    state = []\n","    T = list(set([pair[1] for pair in train_bag]))\n","    \n","    for key, word in enumerate(words):\n","        #initialise list of probability column for a given observation\n","        p = [] \n","        for tag in T:\n","            if key == 0:\n","                transition_p = tags_df.loc['.', tag]\n","            else:\n","                transition_p = tags_df.loc[state[-1], tag]\n","                \n","            # compute emission and state probabilities\n","            emission_p = word_given_tag(words[key], tag)[0]/word_given_tag(words[key], tag)[1]\n","            state_probability = emission_p * transition_p    \n","            p.append(state_probability)\n","            \n","        pmax = max(p)\n","        # getting state for which probability is maximum\n","        state_max = T[p.index(pmax)] \n","        state.append(state_max)\n","    return list(zip(words, state))"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"wtfOQsGq3cBF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592636456186,"user_tz":-270,"elapsed":45230,"user":{"displayName":"Peter YounanoAdeh","photoUrl":"","userId":"06313006438386438224"}},"outputId":"824c2afd-9769-43f6-9c8b-f9a5894a16a9"},"source":["# choose random 10 numbers\n","rndom = [random.randint(1,len(test_datasets)) for x in range(10)]\n","\n","# list of 10 sents to test the model\n","test_run = [test_datasets[i] for i in rndom]\n","\n","# list of tagged words\n","test_run_base = [tup for sent in test_run for tup in sent]\n","\n","# list of untagged words\n","test_tagged_words = [tup[0] for sent in test_run for tup in sent]\n","\n","# Run the test\n","tagged_seq = Viterbi(test_tagged_words)\n","\n","# accuracy\n","check = [i for i, j in zip(tagged_seq, test_run_base) if i == j] \n","\n","accuracy = len(check)/len(tagged_seq)\n","print('Viterbi Algorithm Accuracy: ',accuracy*100)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["Viterbi Algorithm Accuracy:  89.37728937728939\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B2-WYDWr0bJa","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1592636716203,"user_tz":-270,"elapsed":1406,"user":{"displayName":"Peter YounanoAdeh","photoUrl":"","userId":"06313006438386438224"}},"outputId":"a455d8be-17db-4856-ad57-aee514aa5ade"},"source":["# Test on a custom sentance\n","test_sent=\"I am a good boy\"\n","pred_tags= Viterbi(test_sent.split())\n","print(pred_tags)"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[('I', 'PRON'), ('am', 'VERB'), ('a', 'DET'), ('good', 'ADJ'), ('boy', 'NOUN')]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"s9kYJ5jO0fQ3","colab_type":"code","colab":{}},"source":[""],"execution_count":null,"outputs":[]}]}